{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labels = pd.read_csv('./input/dengue_labels_train.csv')\n",
    "total_features = pd.read_csv('./input/dengue_features_train.csv')\n",
    "total_test_features = pd.read_csv('./input/dengue_features_test.csv')\n",
    "total_labels = total_labels.drop(total_labels.columns[[0, 1, 2]], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize(column):\n",
    "    new_column = []\n",
    "    min_val = min(column)\n",
    "    max_val = max(column)\n",
    "    range_val = max_val-min_val\n",
    "    for entry in column:\n",
    "        new_column.append((entry-min_val)/range_val)\n",
    "    return new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_features(data_path):\n",
    "\n",
    "    data = pd.read_csv(data_path)\n",
    "    \n",
    "    # select features we want\n",
    "    features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "                 'reanalysis_dew_point_temp_k', \n",
    "                 'station_avg_temp_c', \n",
    "                 'station_min_temp_c']\n",
    "    \n",
    "    df = data[features]\n",
    "\n",
    "    for title in features:\n",
    "        df[title] = normalize(df[title])\n",
    "\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "#     new_times = []\n",
    "#     for entry in data['week_start_date']:\n",
    "#         entry = entry.split('/')\n",
    "#         if int(entry[2]) > 89:\n",
    "#             entry[2] = '19' + entry[2]\n",
    "#         else: entry[2] = '20' + entry[2]\n",
    "#         newtime = datetime.datetime(int(entry[2]), int(entry[0]), int(entry[1])).toordinal() - 726587\n",
    "#         new_times.append(newtime/7)\n",
    "#     df['new_times'] = new_times\n",
    "\n",
    "    if len(df > 1200):\n",
    "        split_index = 935\n",
    "    else: split_index = 260\n",
    "\n",
    "    new_times = []\n",
    "    for index in range(len(data['week_start_date'])):\n",
    "        entry = data['week_start_date'][index]\n",
    "        if index <= split_index: \n",
    "            new_times.append(datetime.datetime.strptime(entry, '%Y-%m-%d').toordinal()-726587)\n",
    "        else: \n",
    "            new_times.append(datetime.datetime.strptime(entry, '%Y-%m-%d').toordinal()-3715-726587)\n",
    "    df['times'] = new_times\n",
    "    \n",
    "    if len(df > 1200):\n",
    "        return df.loc[:935][:], df.loc[936:][:], new_times\n",
    "    else: return df.loc[:260][:], df.loc[261:][:], new_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Simran/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/Simran/anaconda/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n",
      "/Users/Simran/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "sj_train, iq_train, time = process_features('./input/dengue_features_train.csv')\n",
    "sj_test, iq_test, time = process_features('./input/dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train_subtrain = sj_train.head(800)\n",
    "sj_train_subtest = sj_train.tail(sj_train.shape[0] - 800)\n",
    "\n",
    "iq_train_subtrain = iq_train.head(400)\n",
    "iq_train_subtest = iq_train.tail(iq_train.shape[0] - 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sj_train_subtrain['new_times'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-8e38966da9a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlook_back\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msj_trainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msj_trainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msj_train_subtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'new_times'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msj_testX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msj_testY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msj_train_subtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0miq_trainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miq_trainY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miq_train_subtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-151-dc46f1de8eee>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(dataset, look_back)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mdataX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mdataX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mdataY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlook_back\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "look_back = 1\n",
    "sj_trainX, sj_trainY = create_dataset(sj_train_subtrain.values, look_back)\n",
    "sj_testX, sj_testY = create_dataset(sj_train_subtest.values, look_back)\n",
    "\n",
    "iq_trainX, iq_trainY = create_dataset(iq_train_subtrain.values, look_back)\n",
    "iq_testX, iq_testY = create_dataset(iq_train_subtest.values, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.62659262e-01   3.14679643e-01   4.30091185e-01   4.86238532e-01\n",
      "    0.00000000e+00]\n",
      " [  4.18163999e-01   4.89213301e-01   5.65349544e-01   6.88073394e-01\n",
      "    7.00000000e+00]\n",
      " [  5.86899706e-01   6.57583131e-01   5.65349544e-01   7.43119266e-01\n",
      "    1.40000000e+01]\n",
      " ..., \n",
      " [  7.38484156e-01   8.00486618e-01   6.94528875e-01   7.43119266e-01\n",
      "    5.59800000e+03]\n",
      " [  8.17706632e-01   8.67964315e-01   7.11246201e-01   6.88073394e-01\n",
      "    5.60500000e+03]\n",
      " [  7.36524012e-01   7.94809408e-01   7.93313070e-01   8.89908257e-01\n",
      "    5.61200000e+03]]\n"
     ]
    }
   ],
   "source": [
    "print(sj_train_subtrain.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
